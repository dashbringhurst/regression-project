{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b4568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import wrangle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression \n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404f2afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to print the regression errors for the model\n",
    "def regression_errors(y, yhat):\n",
    "    '''This function takes in two arguments, a previously assigned target variable (y) and the model predictions \n",
    "    (yhat). The function calculates the sum of squares error, explained sum of squares, total sum of squares,\n",
    "    mean squared error, and root mean squared error. It prints strings for each value to the first decimal.'''\n",
    "    # calculate the sum of squares error from the selected variables\n",
    "    SSE = mean_squared_error(y, yhat)*len(y)\n",
    "    # calculate the explained sum of squares from the predictions and the baseline\n",
    "    ESS = sum((yhat - y.mean())**2)\n",
    "    # calculate the total sum of squares\n",
    "    TSS = ESS + SSE\n",
    "    # calculate the mean squared error\n",
    "    MSE = mean_squared_error(y, yhat)\n",
    "    # calculate the root mean squared error\n",
    "    RMSE = sqrt(mean_squared_error(y, yhat))\n",
    "    # print the calculated values for each\n",
    "    print(f'Model SSE is: {\"{:.1f}\".format(SSE)}')\n",
    "    print(f'Model ESS is: {\"{:.1f}\".format(ESS)}')\n",
    "    print(f'Model TSS is: {\"{:.1f}\".format(TSS)}')\n",
    "    print(f'Model MSE is: {\"{:.1f}\".format(MSE)}')\n",
    "    print(f'Model RMSE is: {\"{:.1f}\".format(RMSE)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c8fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to print the baseline mean errors\n",
    "def baseline_mean_errors(y):\n",
    "    '''This function takes in a single argument, y (the target variable) and prints the sum of squares\n",
    "    error, mean squared error, and root mean squared error for baseline.'''\n",
    "    # calculate the baseline sum of squares error\n",
    "    SSE_baseline = mean_squared_error(y, baseline)*len(y)\n",
    "    # calculate the baseline mean squared error\n",
    "    MSE_baseline = mean_squared_error(y, baseline)\n",
    "    # calculate the baseline root mean squared error\n",
    "    RMSE_baseline = sqrt(mean_squared_error(y, baseline))\n",
    "    # print the calculated values for each baseline error\n",
    "    print(f'SSE baseline: {\"{:.1f}\".format(SSE_baseline)}')\n",
    "    print(f'MSE baseline: {\"{:.1f}\".format(MSE_baseline)}')\n",
    "    print(f'RMSE baseline: {\"{:.1f}\".format(RMSE_baseline)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216c32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to determine if the model performs better than baseline\n",
    "def better_than_baseline(y, yhat):\n",
    "    '''This function takes in two arguments, y (target variable) and yhat (model predictions) and calculates the \n",
    "    model SSE, MSE, and RMSE against the baseline. The function prints three strings, one for each result, with a\n",
    "    boolean for whether or not the model value is better than baseline value.'''\n",
    "    SSE = mean_squared_error(y, yhat)*len(y)\n",
    "    SSE_baseline = mean_squared_error(y, baseline)*len(y)\n",
    "    MSE = mean_squared_error(y, yhat)\n",
    "    MSE_baseline = mean_squared_error(y, baseline)\n",
    "    RMSE = sqrt(mean_squared_error(y, yhat))\n",
    "    RMSE_baseline = sqrt(mean_squared_error(y, baseline))\n",
    "    \n",
    "    print(f'Model SSE is better than SSE baseline: {SSE < SSE_baseline}')\n",
    "    print(f'Model MSE is better than MSE baseline: {MSE < MSE_baseline}')\n",
    "    print(f'Model RMSE is better than RMSE baseline: {RMSE < RMSE_baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8e3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(y, yhat):\n",
    "    '''This function takes in two arguments, y (target variable) and yhat (model predictions) and returns a \n",
    "    scatterplot of the residuals of the target variable.'''\n",
    "    residuals = y - yhat\n",
    "    plt.scatterplot(x=y, y=residuals)\n",
    "    plt.xlabel('Home Value')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residuals for Home Value')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f07de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_lars_model(x,y,z):\n",
    "    # create the model object\n",
    "    lars = LassoLars(alpha=1.0)\n",
    "\n",
    "    # fit the model to our training data. We must specify the column in y_train, \n",
    "    # since we have converted it to a dataframe from a series! \n",
    "    lars.fit(x, y)\n",
    "\n",
    "    # predict train\n",
    "    y['tax_pred_lars'] = lars.predict(x)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_pred_lars)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_validate['tax_pred_lars'] = lars.predict(X_validate_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_pred_lars)**(1/2)\n",
    "\n",
    "    print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train, \n",
    "          \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glm_model(x,y,z):\n",
    "    # create the model object\n",
    "    glm = TweedieRegressor(power=1, alpha=5)\n",
    "\n",
    "    # fit the model to our training data. We must specify the column in y_train, \n",
    "    # since we have converted it to a dataframe from a series! \n",
    "    glm.fit(X_train_scaled, y_train.tax_value)\n",
    "\n",
    "    # predict train\n",
    "    y_train['value_pred_glm'] = glm.predict(X_train_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.value_pred_glm)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_validate['value_pred_glm'] = glm.predict(X_validate_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.value_pred_glm)**(1/2)\n",
    "\n",
    "print(\"RMSE for GLM using Tweedie, power=2 & alpha=0\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
